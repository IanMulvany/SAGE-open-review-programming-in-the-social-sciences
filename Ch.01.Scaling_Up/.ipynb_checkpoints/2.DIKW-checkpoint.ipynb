{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (PO)DIKW - A potential theoretical framework for Data Science \n",
    "\n",
    "Social science textbooks often start with some of the interesting findings in the field, the key questions facing social scientists or some controversey to be resolved. Along the way, researchers tend to introduce some of the main theories or tenets of the field. If you're learning sociology, you will hear about Max Weber and rationality or Durkheim and social facts. In Communication, you're likely to hear about medium theory and McLuhan or perhaps Lazersfeld and Two-Step flow of communication. In economics we hear about Pareto and diminishing utility. But what about data science? What frameworks can we use to guide us here? \n",
    "\n",
    "To my knowledge, there's no specific core tenets of data science. We have key thinkers and papers, though these also tend to come from existing domains. And if you are to look for the key papers in data science these end up tending towards being really papers in statistics, machine learning, sociology or econometrics. Yet, when we think of data sceince as a science, it seems that there must be a basis for this? So below is an attempt to consider data science, and particlarly the notion of 'social data science' from a theoretical perspective. \n",
    "\n",
    "Below I draw upon an existing framework from information visualisation called DIKW, or Data - Information - Knowledge - Wisdom. Yet, I preface this with PO to stand for Phenomena and Operationalisation. This is because the world is not filled with data. It is filled with phenomena, which we convert to data through operationalisation. Then once operationalised through measurement or encoding, we can see how it first becomes data and then serves as the basis for information, knowledge, and ultimately, wisdom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data? \n",
    "It turns out that it is even pretty difficult to define data. Originally it meant that which is given or self-evident, from the latin _datum_. In 1946 it was first used to refer to transmissable and storable computer information and less than a decade later was the first use of 'data processing'. Data is a plural but is often written as a singular (which it is here). This is because data is seen as a mass noun, like information or rice. We would say the 'the rice is cooked', by which we almost never mean a single specific grain of rice. Similarly 'the data is being processed' would not refer to a single measurement. While data is a mass noun, we can make it a particular by referring to it as a set. Thus we can say \"data is reliable\" and \"data sets are reliable\". \n",
    "\n",
    "A 21st Century data science should certainly not take data as a given. We have had over a Century of critical thought that should remind people how much goes into any given measurement. For example, let's say we want to measure a frequency of tweeting by gender. Easy - count all the male names and the female names. Or wait, what about androgynous names like 'Alex' or 'Lee'? What about accounts that don't list names? What about group accounts? Even the concept of gender itself is not as easy as considering a binary. Animals can be hermaphrodites and switch genders under some conditions, like differing water temperature or crowding (for some frog species). Individual people can be transgender or present as 'non-binary'. People can be 'assigned male at birth' but definitely feel female. Some people can have extra sex chromasomes or be 'intersex' with some of both male and female organs. All of a sudden, what we thought was a simple binary distinction turns out to be anything but. Adding on top of that is the matter of how closely gender follows sex. Some people believe that gender is determined by sex, whereas many others think that biological sex tends to nudge people towards one gender or another but history and culture do much more to determine it. \n",
    "\n",
    "Right from the get go we are confronted with the first issue in data science, even before we get to data: How to operationalise? Some say the world is full of data. While it is true that the world contains huge amounts of data, the world _is not reducible to data_. Rather, everything we observe is __phenomena__. Everything just is. This perspective comes from William James' notion of radical empiricism, or the idea that everything is real. Dreams are real, myths are real, fantasies are real. If you can think of it, it is real for it has been a thought, even if it has been nothing else. On the other hand, the substance of things might not be what they seem. I am not saying a dragon in a dream is an actual winged scaled lizard. But it definitely is an impression created by the mind that the observing mind recognizes as a dragon. James likes to use the notion of a stick in the water. At the surface of the water, the stick might appear bent. Is it? Yes and no - the stick as an impression in the mind's eye is indeed as bent as it is observed. But the material stick itself might be quite straight. The water makes it appear bent. The bend is not a falsehood; it is a perspective. If you were studying light diffraction in liquids this particlar bend may be of interest. If you were trying to select the straightest stick from a few stuck in the water, this might not be the best measurement. \n",
    "\n",
    "What radical empiricism asks us to confront is the chasm between phenomenon and operationalisation. The world as given is filled with phenomena, a \"blooming, buzzing confusion\" in James' eyes. Lately, scholars have sought to undermine this notion of James'. They note that babies do not arrive in the world as a 'blank slate'. Almost as soon as babies open their eyes, it seems they can identify facees, have phobias, understand some basic mechanics and proprioception (i.e. know where their body is in space xx). But this somewhat misunderstands James' point. Ironically, it means that James' point can be made more forcefully as a consequence. Even the youngest child will already have some cognitive biases in place that intervene in our ability to see the world as it truly is. We as humans have capacities, some of which appear innate and others learned, which enable us to encode the world. Our perceptions are given to us and then strengthened and learned as time goes on. Our perceptions might work for the world at one scale, but not at another. Trying to see the world as it is involves carefully translating phenomena into data rather than simply assuming the world is data. Thinking of phenomena and data as different is an essential skill for thinking critically about the world and thus, for doing research that will lead to new insights and challenge existing understandings. \n",
    "\n",
    "The way that we get from phenomena to data is to __operationalise__. Operationalisation is an extremely delicate and important step in any data science effort. Actually, it is a pretty important part of any scientific research. However, for some disciplines what needs to be operationalised is already given, either because of the nature of the discipline or the nature of the phenomenon. Consider the challenges of operationalisation in psychology. We might ask \"Do extroverts need as much sleep after a party as introverts?\" We know that extroverts are more likely to enjoy the company of others than introverts. In fact, I have heard mention of extroverts as being 'solar powered' while introverts are like having 'rechargable batteries'. But what is an extrovert? Well, it is someone who scores above a certain threshold on an extroversion scale. And why that scale? Because it is seen as reliable. But what about those just below the cut off, are they extroverts? Maybe, but for the purposes of this analysis, no. In this case we simply defer to the work of prior methodologists and give a convenient answer: because they said so. Now the question then actually becomes a little more tedious: \"Do those who score greater than one standard deviation above the mean on a standardised extroversion scale report needing significantly more sleep than those who score one standard deviations below the mean?\" Not only do we not say this because it sounds tedious, but because we often take \"an extrovert\" to mean \"someone who scores greater than one standard deviation from the mean on a standardized extroversion scale\". Is this how everyday people see extroverts? Not at all, but it is a way to provide a consistent measurement. It is an operationalisation of the concept. \n",
    "\n",
    "Psychology tends to have it a little easier than data science in this regard. First, psychometrics tends to focus on scales. There is a recipe for creating a scale: make up a large series of intelligible questions, ask them to people, use a statistical routine to identify which questions seem to be grouped together most of the time (where people who answer yes to one answer yes to the other), then confirm that those questions tend to be answered in the same direction. Create a new variable based on those questions and publish it. If the colleagues who review the paper think that the author(s) went through the steps correctly and the scale makes sense (or explains some other variable) then we are good, our scale is validated, and our concept is operationalised. Thus, while eHarmony (a matchmaking service) says they have models for marital happiness, what they actually measure are the variables that predict to a specific psychometric scale: the Dyadic Adjustment Scale first developed by Spanier in the late 1970s. It has questions like \"xx\" and \"xx\". However, marketing the Dyadic Adjustmet Scale is a lot less appealing than marketing marital bliss.\n",
    "\n",
    "It is less common to see data scientists deploying psychometric questionnaires than it is to see them analysing large blocks of text. Rather than seeking to put people in a lab and isolate a single variable, data scientists treat the world as their lab and try to detect signal from the noise. But in doing so, data scientists are inevitably confronted with operationalisation. For example, imagine you are trying to create a social network of people who email each other in an organization. You want to know whether there are clusters of social groups in the firm that can be identified from email traffic. Does sending a lone email count as a relationship? What about an email and a reply? If you then plot a network of all the emails and replies, it might look like a big, dense hairball; virtually everyone is connected to everyone! Instead, we might _operationalise_ a relationship as involving two separate instances where people send a message to one another. Each instance could be a threaded conversation. Now, is this the 'right' way to operationalise a relationship? It's hard to say. In some cases, we might say yes and others no. What is being contested is not the existence of email nor the existence of relationships but whether the _specific_ critiera of measured email accurately signals a _specific_ kind of relationship. \n",
    "\n",
    "In a similar vein, in criminology we are periodically confronted with spikes in crimes. For example, in 2016 there was a spike in cases of sexual assault in the UK. Was that year particularly notable for sexual predators? No, it was notable because the #metoo movement enabled women to feel empowered to speak about things that were heretofore kept quiet. It's not that the numbers of sexual assaults were increasing. In fact, it is strongly the case that those numbers are gradually decreasing. What changed was the number of _reported_ cases. Simply by leaving out the word 'reported',  journalists can create the impression that a spike in reported cases of sexual assault is due to a spike in the crime rather than a spike in confidence / security for victims.\n",
    "\n",
    "A key concern with operationalisation is when people confuse data for phenomena. Gender is the social manifestation of sex dimorphism, but when we take gender to mean sex we forget about all the edge cases and exceptions. When we take crime statistics as data, we can forget about the many unreported crimes that occur. Consider that for all the drugs that are caught at the border, an _order of magnitude_ more are not caught. Thus, measuring drug use by the amount of drugs seized could lead to some very tenuous numbers. \n",
    "\n",
    "As social creatures we do not live outside of the world from which our data emerges. But it is sometimes easy to forget that because we are wrapped up in our practice. For example, take the notion of being a Latinx person. This is now a very clear identity, with conferences, groups, protected census categories and so forth. Yet Latino and Latina categories only emerged in the Twentieth Century, primarily in America as a means of identifying a group of individuals that evidently marked an important group, yet would not otherwise be identifiable by racial categories. Latinx persons can identify racially in a number of ways. But on the other hand, the label is contested by some. There as never been a Latino state or Latina nationality. Thus it is unsurprising that the vast majority of Brazilians would refer to themselves as Brazilian and not Latin American xx. But does Latinx have explanatory power? Yes, indeed. \n",
    "\n",
    "Explanatory power, however, doesn't come from data itself. It comes from __insight__ about data. But how do we get from data to insight? That's the second half of this section. Here we draw upon a framework from information visualisation, calld DIKW. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Data to Wisdom. \n",
    "Above we discussed the transition from phenomenon to data. This involves the use of operationalisation to identify how to encode phenomena. Data then is a product of measured observation. \n",
    "\n",
    "An often repeated framework in information visualization is that there is a hierarchy from data to wisdom. \n",
    "\n",
    "- **Data** refers to that which was measured and encoded in some means. \n",
    "- **Information** refers to a presentaiton of that data that signals differences we would understand. \n",
    "- **Knowledge** is being able to understand the interrelatedness of the information (i.e. signals). If we can convey information in a graphic to another person we can give them knowledge. \n",
    "- **Wisdom** is challenging to define. In this domain I like Alberto Cairo's definition (from \"The Functional Art\"): Wisdom is \"deep understanding of acquired knowledge, when we not only “get it,” but when new information blends with prior experience so completely that it makes us beter at knowing what to do in other situations, even if they are only loosely related to the information from which our original knowledge came. Just as not all the information we absorb leads to knowledge, not all of the knowledge we acquire leads to wisdom\" (P. 17). \n",
    "\n",
    "We are trying to turn data into knowledge by identifying information (statistically or otherwise) that we can convey to an audience. We make the researchers wise as they understand how this knowledge relates to their existing frame of reference and possible future phenomena. \n",
    "\n",
    "Going from data to information is, loosely speaking, a matter of signal detection or pattern detection. Imagine opening up a corrupted file on a computer and seeing each of the three series of numbers below: \n",
    "\n",
    "0 1 0 1 0 1 0 1 0 1 0 1 \n",
    "\n",
    "1 1 1 1 1 1 0 1 1 1 1 1 \n",
    "\n",
    "0 0 1 0 1 1 1 0 0 1 0 1 xx\n",
    "\n",
    "What was in the original file? The first one is a repeating sequence. If there's a 0, the next number is a 1. The second one appears to be nothing but 1 except for a single 0, the third one appears to be random or a bit of a jumble. Information here is about understanding the signals from the noise. In the first case, there is not much information after the first few digits. In the second one, there is an anomoly in an otherwise steady state. In the third one it appears to be random. \n",
    "\n",
    "In all three cases there is some information to be gleaned. The first series is repeating, the second is consistent with some fluctuation and the third appears to be random. Thus, we can use this information to communicate something to someone else. Yet, what if it turns out that the third one actually means something? If we understand the use of binary we can start to ask, is this representative of a type of information? What else uses zeros and ones and is this the application of such an encoding? The third sequence might be the beginning of a string of numbers representing something else. Wisdom is about understanding how the knowledge that we gain can be applied to other domains. \n",
    "\n",
    "The point here is that understanding what is data does not have to happen right away and it might not be obvious just by looking at the data. First, we have to identify the information from that data and then understand how that information relates to its context, thus creating knowledge. Finally, if we can transport that knowledge from one context to another, we are getting closer to wisdom. \n",
    "\n",
    "Many times in social data science, we see people rush to create information but in doing so, rush right past contextual features that would create knowledge. The analyst was smart, but not necessarily wise. We can see this today in the world of analytics. We can learn how many tweets were sent, classify the number of words, see which ones are most common, plot the time when people are most active and so forth. For example, trying to learn about the experience in a hotel by sorting the words used in reviews might be illustrative, but not necessarily insightful. It is when these data are situated in their context that it becomes the most interesting. There in the hotel reviews we might learn of a specific underperforming employee or some notable external factor like roadworks that could make the difference. \n",
    "\n",
    "This is not to give short shrift to data analytic techniques. This is from social science to data science after all, not the other way around. The techniques for clustering, sorting, combining and otherwise managing information are a necessary precursor to the sorts of insights that we get from learning about information in its context. Why? Because they allow us to see the data at different scales. These are the data wrangling and data analysis tasks that help bring insight. But the true insight comes not from being able to _look at scale_ (as in 'look at all this data I can manage on a server'), but being able to _see at scale_ (as in 'now once we clean, filter, and plot, the pattern is obvious'). \n",
    "\n",
    "So, first I'm here to show you how to look and then, hopefully, I can help show you how to see. And to start, let's think about what it means to manage data systematically, that is to say, what does it mean...to code? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
