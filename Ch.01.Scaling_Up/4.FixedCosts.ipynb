{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed, variable, and Marginal Costs: Why not to build a barn.\n",
    "\n",
    "I don't know where I first heard this joke, but I like it and I've been known to tell it in my programming classes:\n",
    "> Why don't you ask a computer scientist for a glass of milk? Because they will build you a barn and fill it with cows just to make the second glass that much easier to get. \n",
    "\n",
    "The idea behind the joke is that computer scientists will --by default-- venture into a level of abstraction that is not really necessary. Get a jug of milk or a carton from the store, you might say. It is quicker, simpler, and definitely cheaper than building a barn. But then would _anyone_ go through all the trouble? The idea behind building the barn is not about the second glass of milk but about the $n^{th}$ glass. That is, all glasses after the first one. Drafting the program to get the first glass would be the fixed cost in this case. The marginal costs is the cost per iteration, in this case, the cost of getting any given glass once the system is set up. The joke works because we perceive the fixed cost to be somehow irrational - in this case the difference between going to the store and buying a carton of milk and literally sourcing some cows (or growing almonds or oats if your guests prefer different kinds of milk). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Economics to Data Science \n",
    "\n",
    "One central part of microeconomic theory is the identification of fixed and marginal costs of production. It's a very useful set of concepts for programming as well. However, where microeconomics often (but not necessarily) speaks in terms of the value of money or capital, here we can think in terms of human effort or time. \n",
    "\n",
    "The reason that we work with computers is often to facilitate work that can happen at greater time scales. Processors can do the same repetitive task much more quickly and accurately than a human. That time savings allows us to see the aggregated results from many calculations. This is exciting because it allows us to get a characterisation of things at scales that we otherwise would be unlikely to perceive or do so without great effort. For example, we now have weather stations that can make forecast models on demand for different parts of the country. Instead of one meteorologist per city, we have a system in place of readings that get synced. Public access to these readings means that third party apps can use them to calculate a weather report for anywhere that is near enough to the readings. \n",
    "\n",
    "The weather reading set up was the same in both case. A few barometers, some thermometers, and so forth. This is the fixed cost. These days that fixed cost includes sending up a satellite. It can be very costly. But the marginal costs can vary considerably. If you need another weather reading in a city between London and Birmingham, you need another meteorologist. However, if you have a series of readings across the country and an algorithm for predicting weather based on it, you simply feed in the readings and out comes the forecast. Is it as good as a meteorologist? Well, not always. It is as good as the algorithm. What we have done is take a task that can scale slowly with human effort and then make it scale quickly using algorithms.\n",
    "\n",
    "I've heard before that computer scientists only know how to count three numbers: $0$, $1$, and $n$. The idea here is that if you have to do it twice, you really have to do it $n$ times, and we should be able to specify some algorithm that allows us to do it $n$ times. In reality there are still lots of issues with efficiency. But indeed, this is a foundational lesson in programming: \n",
    "> where possible shift marginal costs to fixed costs, but not if it will add overall costs.  \n",
    "\n",
    "These, then are costs to time; either time spent writing repetitive code or time spent running that code. I see this a lot when people first learn loops and functions. They get the revelation that abstraction can help with repitition. See below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernie.Hogan Scott.Hale\n"
     ]
    }
   ],
   "source": [
    "# Name from email\n",
    "email1 = \"Bernie.Hogan@gmail.com\"\n",
    "email_parts = email1.split(\"@\")\n",
    "name1 = email_parts[0]\n",
    "\n",
    "email2 = \"Scott.Hale@oii.ox.ac.uk\"\n",
    "email_parts = email2.split(\"@\")\n",
    "name2 = email_parts[0]\n",
    "print(name1,name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bernie.hogan', 'Scott.hale', 'Taha.Yasseri']\n"
     ]
    }
   ],
   "source": [
    "# Attempt number 2\n",
    "email_list = [\"bernie.hogan@gmail.com\",\"Scott.hale@oii.ox.ac.uk\",\"Taha.Yasseri@oii.ox.ac.uk\"]\n",
    "names = []\n",
    "for email in email_list: \n",
    "    names.append(email.split(\"@\")[0])\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that not only is attempt number 2 shorter, but that it includes a third email address. It takes the operations from the first section, puts them in a ```for``` loop and spits out the result in an array. If we were to add a new email to the first attempt, we would have to copy and paste or write new code from scratch. In the second example, we simple add a new email to the list and the rest will work as intended with no extra tweaking. In that sense, the first one adds more fixed costs because we have to write more code. The second one does not because we can use the same code with more data. \n",
    "\n",
    "In computer science terms we might say that the second example has code that is more abstract, modular, and reusable. These are all things we want out of our code. But what we really want is to make our analyses as complete and efficient as possible. And recall that what we want to minimise is not simply length of code, but time taken in the analysis. So that's where the joke comes in -- building a barn represents an attempt at making the get_milk routine more reusable, but in such an over-the-top way that it seems like the emphasis on fixed costs have gone too far. Recall, in data science we are often not writing fully fledged production code but code that works for our analysis. Thus, we want to optimise fixed and marginal costs rather than do everything by hand (maximizing marginal costs) or create the super-analyzer 2000 that has every possible feature but is so unwieldy that it might never get off the ground. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenges of maximising fixed costs \n",
    "\n",
    "Rarely in a computer science text will you hear about the virtues of code that is a one-off, or just hacked together. I do not want to change that, necessarily. However, I do know that I have seen code that is often far more overwrought and abstract than it needs to be. For example, the push towards object-oriented programming is excellent for some tasks, but I often have trouble finding opportunities to articulate user-defined objects to students in ways that actually help their analysis, even if it helps their code architecture. \n",
    "\n",
    "To help with this so that we are neither going to spend too much time planning and building that barn nor are we going to do it all by hand, I have a series of pointers here. I would love to add more to these but I think it's a start. \n",
    "\n",
    "1. __Psuedocode sections of your analysis before embarking upon it__: This way you can discover data you might need or methods that you can treat as black boxes. This is covered later in this chapter.\n",
    "2. __Refactor your code during your analysis, not after__: Refactor is a way of taking repetitive or messy code and writing it in a way that makes it more elegant and ideally more robust. It is okay to spend an afternoon on your code midway or late in your analysis and just redo the code. Sometimes you only know how to do certain things after having done them, or you only know what is repetitive once you start on them and discover all the commonalities. If you have budgeted time to refactor, it will definitely pay off when you have to come back to the code, extend it, or share it with others. \n",
    "3. __If you can do it by hand in a few minutes, do it, but document it__: Accept that sometimes it is just easier to recode a few variables by hand than try to find a regular expression or other mechanism for automating this or discovering a more abstract way. \n",
    "4. __Do not treat your analysis as the basis of a huge project for others__: Time and again, I have seen people slowed down by the sense that they need to create a code base that will not just be used for their analysis but for others in the field. The intention is admirable but the realisation often gets in the way of doing a quality analysis. The best way to get your work reused is to have a paper published that others can cite. Thus, in all cases, I strongly recommend doing one-off analyses for yourself or your group and accepting that this code is not going to go very far. It should still be readable, serviceable, and well commented...for you and your team. But get some projects under your belt first and ideally contribute to other people's projects to get a sense of what it means to get your software used by others. You will discover a whole host of things you might not have considered (and admittedly that we can't cover in this book).  \n",
    "\n",
    "Beyond these pointers, we can use the notion of FREE coding as a guide for our code to help us understand what to prioritise and what will be most effective in helping us accomplish our goals. This is covered in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
