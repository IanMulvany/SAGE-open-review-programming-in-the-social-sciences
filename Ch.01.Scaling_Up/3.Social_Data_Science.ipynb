{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond the interface \n",
    "\n",
    "This is a book about some of the fundamental skills for social data science [SDS]. At the risk of being terribly reductive, social sciences tend to focus on individuals as thinking persons, with *agency*, and aggregations of persons, as *structure*. It might be how individuals alter their behaviors in markets based on market signals, how political movements form and position themselves, or users on social media platforms have their behavior nudged. In these cases as in many more, much of the activity associated with these phenomena that we consider social is now mediated. There's traces of tickets to events, often with specific names and accounts, held on servers bby concert vendors. There's data on electricity use monitored using smart home gadgets. Companies regularly clean and distribute data sets as challenges. Even the social sciences are getting in on this. Matt Salganik at Princeton ran the 'Fragile Familes' challenge in 2018 to see how data on children at two waves could predict measures such as grades or psychometric values in a third wave. Wikipedia offer a wealth of open access data and even some corporate social media allow programmatic access to streams of content. \n",
    "\n",
    "There is indeed an explosion of data available or at least created. Some of this data is not available because of privacy or privitisation. But we can still think about this data as being able to make claims about the world. \n",
    "\n",
    "The goal of this book is to get you thinking and doing things differently. In particlar, we want you to think beyond the interface. Facebook is not merely the page with the long newsfeed and the blue banner at the top. It is also a data controller (that's the legal term). It hosts data, presents it in a particularly curated way, regulates who gets to see what data and who doesn't. But as a user of Facebook's products, one might be inclined to think Facebook _is_ the newsfeed. But it's not. The newsfeed is just a representation of the data being held by Facebook. It's a form of algoriithmic curation. And that curation is based on decisions, ideas, and tests. But it's also historically contingent...it did not have to be that way. And it is but one view to the lived experience that is captured in these posts, replies, photos, and videos. To think beyond the interface is to think - how can the data we see and record be represented in a different format, a format that can help us answer questions about the world. \n",
    "\n",
    "The way people often think beyond the interface is to translate data from one representation to another. We might start with a list of friends. That's a single, unordered, column of data: \"Alice\", \"Bob\", \"Chuck\", and \"Dee\". Now, imagine layering on just one more kind of data. It could be birthdays, it could be their profile summary, it could be their friendships between each other or where they live. In each case, you could represent the people different. We could see that Alice and Bob live in the same city or that Chuck and Dee are friends with each other. We might discover that they all have birthdays in the spring or that you message these friends most in the summer and the winter but not the spring or fall.  \n",
    "\n",
    "Answering these questions is available with the data already on Facebook, but not in the form that Facebook provides. Unfortunately, Facebook do not provide easy programmatic access to data. In fact, they have explicitly sought to close off access to data where possible (xx Hogan 2018). But Faebook still works well as an example and who knows. Maybe they will hire you as a reserch scientist someday and from within the company you might have access to all kinds of information. So imagine instead Alice, Bob, Chuck and Dee all send each other eamil instead. We can still layer this data, use it to see patterns at a different sccale and to ask questions about the people in particular or their contexts in general. \n",
    "\n",
    "The point is to think \"beyond the interface\" and in doing so think about what other reprensetations of people are available and when we observe these representations what else will we learn. Sometimes we will see patterns, sometimes we won't. Some of those patterns will be coincidences, but some will point to an interesting feature about the data and one worth probing further. To do this, however, involves applying some programming skills to the data at hand. Programming certainly isn't the only way to do this, but it is quite powerful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we think of data science, people often think of machine learning. But data science involves considerably more than machine learning. That's not to dismiss ML. It's amazingly powerful and sometimes completely bonkers. But getting the data ready for machine learning, first through data access and then through data wrangling, are critical parts of the puzzle. They are often the less glamourous parts, but they are also some of the most carefully done and intensely scrutinised. This is because they are the parts of the research process where the researcher must exercise the most judgment. This is not an either/or proposition. But it is to suggest that some parts of data science can keep algorithms as black boxes. Machine learning can be done in a bit of a black box fashion. When we get results that make sense or seem to be useful given our various goodness of fit metrics, we can often ignore the specifics of the process that got us there. This is not to be naive about them, but to understand our limits. \n",
    "\n",
    "On the other hand, there's virtually nothing black box about data access and wrangling. In the code that follows there will be a handful of places where we simply ask the computer (i.e. \"call a method\") in a way where it does not really matter if we understand the precise implementation of a task. But for the most part, every operation must be carefully told and deliberately stipulated. In the pages that follow, I will be discussing not merely programming. It is better thought of as the art of asking and answering systematic questions. The thing is, most programmers I know do not have perfect or even great memories. While coding is like a language, its one where there are lots of phrases that are hard to rattle off by heart and remember when needed. Instead, people make use of a huge volume of online resources, books like this one, searching the web, asking questions in forums and in chat rooms. The programming will come with time. And with some small successes behind you, you too will start to have ever greater successes. \n",
    "\n",
    "The challenge is not how to program, but _what_ to program. Often when problem solving code issues with students, I would ask 'what do you want to do' not 'do you know how to use this or that method'. Because when we break it down, it often comes together coherently, and then getting to code to run is more a matter of fiddling with syntax than anything else. On the other hand, sometimes, data is structured in a really peculiar way or simple a way not amenable to the sorts of questions you want to answer. But by keeping an eye on what question we want to answer we can more directly focus both the data cleaning and the potential analytical approaches.  \n",
    "\n",
    "Much of this work thus centers around the twin instruments of the social scientist's trade: *operationalisation* and *research questions*. Strangely though, we won't be talking too much about these topics in detail for a while. Although research questions come as second nature for a seasoned researcher, students often struggle coming up with good research questions right away. Some have a knack for this, but others often have either a specific skill they simply want to employ or just a domain that they want to learn more about. What we want to foster in the first half of this book is a playful approach to the task of capturing insight from data. Such an approach should allow students to explore data, ask questions, and warm up to the data itself. Then, once comfortable 'in the sandbox' so to speak, we can start focusing our questions, checking our biases and thinking about how to put together research that doesn't simply *describe data* but *explain phenomena*. \n",
    "\n",
    "## Building a socialscope\n",
    "Phenomena for social scientists often happens at scales that we do not normally perceive. Like in the example of layering data on to a list of friends, the implication is that we will learn something about the friends by thinking about these friends as a collection or an aggregate. Perhaps this is because we can detect some similarity between all four, or some regularity in the behavior of these friends either with each other or with you, the person who knows these friends. We can say these regularities happen at scale.\n",
    "\n",
    "Scale is an extremely important concept for data science. Sometimes things only work at small scales or large scales, they work for certain time periods but not others. Scale, in that sense, is like helping to determine how far out we can extend our findings. In history, there is the concept of ideographic and nomothetic writing. Idiographic writing is about the specifics and the details of an event; which minister introduced what bill or how did that person express their ideas on that comment board. Nomothetic writing is about ascertaining the general laws or patterns that extend across contexts. Soemtimes when we zoom out to be totally nomothetic we can learn really fascinating things about the world, but we might actually lose sight of some of the processes, how they are experienced and how people make meaning of the context. Some disciplines are extremely nomothetic, such as physics. Others are extremely idiographic, such as ethnography. We are not here to judge, but to facilitate. For those doing detailed word in text, are they collecting the right text, are they interpreting comments in relation to what came before or after? Are they looking at enough text to tell a story? Enough to train a classifier? Enough to train a neural network? Thinking about building a socialscope means thinking about capturing the right scale. The things you learn with a microscope are very different from what's learned from a radio array or an orbit-based telescope. All have their place but all similarly have limitations. \n",
    "\n",
    "Now when using the metaphor of a scope, we are implicitly conjuring ideas about objects; material things in the world. We might think if a microscope as looking at cells or telescope as viewing a planet. But this is where we need to use a little caution in our metaphors. The things in the world that we look at in social science are not always material. Sometimes they are latent, implied, or abstract. For example, consider political orientation. When people vote, they are deciding on their selection between very real candidates and very real established parties. But how well do these parties represent not just the people, but their will? People have political leanings, values, ideas, and concerns that are not always perfectly aligned with parties. It's okay for this to be the case. Politics is not simply about the contest of wills between clearly stipulated sets of ideas, but the determination of these ideas at the macro level through the processes of electioneering and governance. In this sense, structures such as contests for who to be party leader or who to run for office become tasks in operationalising. We stabilise on a decision based on data. We say things like, \"she received the majority of votes, so she should be the representative\". Does that mean she will represent everyone? Does that mean she will be a fair representative? No. It means that we went through a process where a claim was uncertain. Then according to some rules it became less uncertain. The representative then should not be seen as the 'true' person that perfectly represents that district. We do not even know that she will be a good representative, though we have some ideas. Maybe it doesn't matter as long as the other guy did not get to become the representative. In this sense, it is hard to say that the election was necessary. Rather it was contingent. It was contingent on people, their history, and the many factors that went into messaging about candidates. Thus, some of the claims we can make about the election will likely be ideographic. They will tell *the story* of that election. But some will tend to be more nomothetic, like whether people feel a sense that immigrants are taking their job are likely to vote for a candidate who 'incentivises inequality' (for example by opposing redistributive funding that might be used to help new immigrants adjust or integrate). This gives us a clearer picture of the various wills and factions within the group. \n",
    "\n",
    "Strictly speaking, this is not a book on social science research methods. But that's only partially by design. Rather, to some extent it is by necessity. The social sciences have a set of skills that does not always lend itself to making many of the judgments required for social _data_ science. For example, think if how many questions are asked in the way they are because it works for a survey; further, works for a survey over the phone. For questions such as how trolling undermines faith in political institutions, we cannot get a clear answer through a survey or representative sample. We can get a population level estimate of the frequency of the behavior or perhaps public opinion on trolling, but this is not the same thing. Asking the public whether they prefer cake or pie will not lead you to learning how to bake a good pie, only which pies the public define as better than others. We are here to (metaphorically) bake pies.  \n",
    "\n",
    "Imagine if, instead of asking the public which pies the prefer, we go to a recipe site and see which pie is most popular. It's not quite the same thing. As soon as we go to that recipe site someone is going to start asking questions, tough questions. This is a shame, because we were just talking about pie. But as soon as we shift to making claims about pie those claims are going to get tested. What's the most popular pie is not necessarily the same as the best. The best pie, by taste, might actually be incredibly difficult to make. Further, the best pie for those whose palette prefers tart will not be the same as those for whom their palette prefers sweet. What about the best pie hot versus cold? Have popular pies changed over the years? In the 1970s I hear that key lime pie was a popular dish. These days salted caramel seems to be all the rage. So again, what's the best pie?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answering these questions does not necessarily involve the most complex statistics or the newst algorithms. Sure, give a learning algorithm enough data about you and it might be able to determine the best pie for you personally. But that might not get you any further into making claims about what makes some pies, in general, better than others. Better for what? Sometimes when the what is clearly specified, the how becomes straightforward. \n",
    "\n",
    "When we say better for what we are already on our way to clearing up our methodology. Better for taste...well taste is pretty subjective, so we might want reports from people. Better for calories? Well, we can measure the calories in a serving. Better for novice bakers? We can look at prep time, number of steps or number of ingredients. Better for budgets, again, same thing - perhaps cost of ingredients. But even then, the cost will vary depending on where you live; fresh berries in the summer in the UK will cost much less than greenhouse fresh berries in the winter. So, even then, while we specified better for what, that might not have been far enough.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the pie example is really getting at is that *operationalisation* is important. When we operationalise we take some concept of interest and transform it in such a way that we can ask questions about it at the scale in which we are interested. \n",
    "\n",
    "In many senses, social data science then is the science of operationalisation. It is the science of taking data that is often objective but partial and using it to answer questions that enable us to talk about the world in scales beyond standard human experience. When we classify, we are operationalising concepts as soon as we decide what to train on and how to split the sample. We when are doing network analysis, text mining, regressions, or just descriptives, a large amount of our time will be spent articulating what it is that our data represents and what we think it represents. \n",
    "\n",
    "Reconciling measurement and phenomena is not exclusive to social data science, but it is central to papers in this field. If we want to measure bullying online we first have to find a way to measure it, then a way to do such measurements at a scale that we think allows for meaningful claims. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Socialscopes needs scale \n",
    "\n",
    "Up to this point I have spoke primarily of research design, which seems pretty far from code. But for the rest of the chapter (and indeed the rest of the early part of this book) we will be dealing with the nuts and bolts of programming. I want to suggest that the programming parts are not actually too far from this discussion. In the next couple sections in this chapter I'll be discussing some of the art of programming. The idea here is to get you thinking about the practice of doing research as a practice of crafting means to see things at scale, as well as to understand what is the right scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
