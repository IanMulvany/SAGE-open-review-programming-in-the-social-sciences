{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Sheet. Chapter 3: Getting Data into DataFrames\n",
    "\n",
    "**Book: From Social Science to Data Science** \n",
    "\n",
    "**Author: Bernie Hogan**\n",
    "\n",
    "**Last revision: September 19, 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "filein = open(\"..{0}Data{0}test.txt\".format(os.sep))\n",
    "print(filein.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for your own operating system:\n",
    "# Which will work? \n",
    "\n",
    "try: \n",
    "    filein = open(\"..\\Data\\test.txt\")\n",
    "    print(filein.read())\n",
    "except FileNotFoundError:\n",
    "    print(\"If you are on windows then your files are not in the right folder\")\n",
    "    print(\"If you are on Mac or Linux, then disregard.\")\n",
    "    \n",
    "try: \n",
    "    filein = open(\"../Data/test.txt\")\n",
    "    print(filein.read())\n",
    "except FileNotFoundError:\n",
    "    print(\"If you are on Mac or Linux then your files are not in the right folder\")\n",
    "    print(\"If you are on Windows, then disregard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON - JavaScript Object Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os \n",
    "\n",
    "filein = json.loads(open(\"..{}Data{}muppetEpisodes.json\".format(os.sep,os.sep)).read())\n",
    "\n",
    "print(type(filein)) # This shows it is a dictionary, so let's ask for keys. \n",
    "      \n",
    "print(filein.keys()) # Perhaps we want to explore the 'data' key. \n",
    "\n",
    "print(type(filein['data'])) # It would appear 'data' is a list. \n",
    "\n",
    "print(len(filein['data'])) # This list has 100 entries. \n",
    "\n",
    "print(filein['data'][0].keys()) # Inspect the keys - these will go in our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filein['data'][0]) # Let's view the first entry. It's very long with a summary and other details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will normalise the JSON so that it can be used as a table. We will display the table here on the screen but you will notice that it is too long for the screen size. Below that we will look at the column headers and then select a smaller number of them to display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "muppetjson = json.loads(open(\"..{0}Data{0}muppetEpisodes.json\".format(os.sep)).read())\n",
    "muppetdf = json_normalize(muppetjson[\"data\"])\n",
    "display(muppetdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,i in enumerate(muppetdf.columns):\n",
    "    print(c,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(muppetdf.iloc[:,[7,13,27]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markup languages: HTML and XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4,os\n",
    "\n",
    "wikiHTML = open(\"..{0}Data{0}Canada_Wiki.html\".format(os.sep),'r').read()\n",
    "print(len(wikiHTML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wikiHTML[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Make the soup \n",
    "soup = bs4.BeautifulSoup(wikiHTML, 'html.parser')\n",
    "\n",
    "# Query the soup\n",
    "print(soup.title.text)\n",
    "links = soup.find_all(\"a\")\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "internal_links = []\n",
    "\n",
    "for souplink in soup.find_all('a'):\n",
    "    link = souplink.get('href')\n",
    "    if link: # That means the link is a hypertext reference and not a section heading\n",
    "        if 'http' in link:\n",
    "            urls.append(link)\n",
    "        else:\n",
    "            internal_links.append(link) \n",
    "    else:\n",
    "        print(souplink)\n",
    "\n",
    "print(len(urls),len(internal_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in internal_links[:10]: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "wikiLinks = pd.DataFrame(internal_links,columns=[\"internal_links\"])\n",
    "\n",
    "def get_wiki(text):\n",
    "    if text[:5] == \"/wiki\": return True\n",
    "    else: return False\n",
    "    \n",
    "wikiLinks[\"wiki\"] = wikiLinks[\"internal_links\"].map(lambda x: get_wiki(x))\n",
    "wikiLinks.head(10)\n",
    "\n",
    "print(\"There are {} internal links on this page, {} of which are unique, and {} of which are to other wiki pages\".format( \n",
    "        len(wikiLinks[\"internal_links\"]), \n",
    "        len(wikiLinks[\"internal_links\"].unique() ),\n",
    "        len(wikiLinks[wikiLinks[\"wiki\"]]) #Notice here I sliced to only \"wiki\" == True.\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(wikiHTML,'lxml') #res.content\n",
    "tables = soup.find_all('table')[0] \n",
    "parsed_tables = pd.read_html(str(tables)) # This will return a list of DataFrames, one for each table detected.\n",
    "print(len(parsed_tables)) # This will show us there is only one table detected. \n",
    "display(parsed_tables[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading some xml\n",
    "import bs4, os\n",
    "\n",
    "infile = open(\"..{0}Data{0}Canada.xml\".format(os.sep),'r')\n",
    "\n",
    "wikitext = infile.read()\n",
    "\n",
    "# Note: In some circumstances, the file is saved as encoded data, in which case\n",
    "# use the .decode('utf-8') function on the text. As in:\n",
    "# soup = bs4.BeautifulSoup(wikitext.decode('utf8'), \"lxml\")\n",
    "soup = bs4.BeautifulSoup(wikitext, \"lxml\")\n",
    "\n",
    "print (soup.mediawiki.page.revision.id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"\\n~~~~~\\n\"\n",
    "\n",
    "for i in soup.children: print(i.name)\n",
    "print(sep)\n",
    "for i in soup.html.children: print(i.name)\n",
    "print(sep)\n",
    "for i in soup.html.body.children: print(i.name)\n",
    "print(sep)\n",
    "for i in soup.mediawiki.children: print(i.name) \n",
    "print(sep)\n",
    "for i in soup.mediawiki.page.children: print(i.name)\n",
    "print(sep)\n",
    "# I discover that we can just say soup.page and it will get the text. \n",
    "y = soup.page.text\n",
    "\n",
    "print (soup.page.text == soup.html.body.mediawiki.page.text)\n",
    "print(y[:100],\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,os\n",
    "\n",
    "with open('..{0}Data{0}MuppetsTable.csv'.format(os.sep), newline='') as file_to_read:\n",
    "    filereader = csv.reader(file_to_read, delimiter=',', quotechar='|')\n",
    "    for row in filereader:\n",
    "        row = [\"{:<20}\".format(x) for x in row]\n",
    "        print(\"\".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('..{0}Data{0}MuppetsTable.csv'.format(os.sep))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os \n",
    "\n",
    "mt = pd.read_excel(\"..{0}Data{0}MuppetsTable.xlsx\".format(os.sep))\n",
    "display(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "x = ['1','2']\n",
    "pickle.dump(x,open(\"temp.txt\",'wb'))\n",
    "y = pickle.load(open(\"temp.txt\",'rb'))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
